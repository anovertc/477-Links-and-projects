{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg2xaihqKshR"
      },
      "source": [
        "# Lab5 Deep Learning\n",
        "In this lab there are three parts including a complete implementation pipeline for using deep neural network on multi-class classification task.\n",
        "\n",
        "For each part, you should read through it and include it to your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5u22TALxKshT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6ORWBq1vKshU"
      },
      "outputs": [],
      "source": [
        "## download dataset\n",
        "if not os.path.exists('Celebrity_Faces_Dataset'):\n",
        "    remote_path = 'https://github.com/Michigan-State-University-CSE-440/logistic-regression/releases/download/v1.0/Celebrity_Faces_Dataset.zip'\n",
        "    local_path = 'Celebrity_Faces_Dataset.zip'\n",
        "    if not os.path.exists(local_path):\n",
        "        os.system(f'wget {remote_path}')\n",
        "    os.system(f'unzip {local_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmG9_OnVKshU"
      },
      "source": [
        "## Part 1:  Define Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ng-pTURoKshU"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_channels=1, num_classes=10, image_size=(28, 28)):\n",
        "        \"\"\"\n",
        "        A polished two-layer convolutional neural network with normalization.\n",
        "\n",
        "        :param input_channels: Number of channels in the input images.\n",
        "        :param num_classes: Number of output classes.\n",
        "        :param image_size: Tuple (height, width) of the input images.\n",
        "        \"\"\"\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # First convolutional block\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),  # Normalization layer\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Second convolutional block\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),  # Normalization layer\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # After two pooling operations, the height and width are reduced by a factor of 4.\n",
        "        conv_output_height = image_size[0] // 4\n",
        "        conv_output_width = image_size[1] // 4\n",
        "\n",
        "        self.classifier = nn.Linear(64 * conv_output_height * conv_output_width, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        # Flatten the tensor for the fully connected layer.\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qWQeh9Q2KshV"
      },
      "outputs": [],
      "source": [
        "# CNN classifier that mimics the API of the from-scratch logistic regression class\n",
        "class CNNClassifier:\n",
        "    def __init__(self, learning_rate=0.001, num_epochs=10, batch_size=64, seed=42,\n",
        "                 input_channels=1, image_size=(28, 28), num_classes=10):\n",
        "        \"\"\"\n",
        "        :param learning_rate: Learning rate for the optimizer.\n",
        "        :param num_epochs: Number of epochs to train.\n",
        "        :param batch_size: Batch size for mini-batch gradient descent.\n",
        "        :param seed: Random seed for reproducibility.\n",
        "        :param input_channels: Number of channels in the input images.\n",
        "        :param image_size: Tuple of (height, width) of the input images.\n",
        "        :param num_classes: Number of output classes.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.seed = seed\n",
        "        self.input_channels = input_channels\n",
        "        self.image_size = image_size\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        torch.manual_seed(seed)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f'Using device: {self.device}')\n",
        "        self.model = SimpleCNN(input_channels, num_classes, image_size).to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_epoch(self, X, y):\n",
        "        \"\"\"\n",
        "        Train the CNN classifier.\n",
        "        :param X: Input images as a NumPy array of shape (N, C, H, W).\n",
        "        :param y: Labels as a NumPy array of shape (N,).\n",
        "        \"\"\"\n",
        "        # Convert the NumPy arrays to PyTorch tensors.\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.long).to(self.device)\n",
        "\n",
        "        # Create a dataset and dataloader for mini-batch training.\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        self.model.train()\n",
        "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "            batch_X = batch_X.transpose(3, 1)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(batch_X)\n",
        "            loss = self.criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        return avg_loss\n",
        "\n",
        "    def validate(self, X, y):\n",
        "        \"\"\"\n",
        "        Predict class labels for the given input images.\n",
        "        :param X: Input images as a NumPy array of shape (N, C, H, W).\n",
        "        :return: NumPy array of predicted labels.\n",
        "        \"\"\"\n",
        "\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.long).to(self.device)\n",
        "\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        batch_preds = []\n",
        "        batch_gt = []\n",
        "        loss_tot = 0.0\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "                batch_X = batch_X.transpose(3, 1)\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                pred = torch.argmax(outputs, dim=1)\n",
        "                batch_preds.append(pred)\n",
        "                batch_gt.append(batch_y)\n",
        "                loss_tot += loss.item()\n",
        "        avg_loss = loss_tot / len(dataloader)\n",
        "        y_pred = torch.cat(batch_preds, dim=0).cpu().numpy()\n",
        "        y_gt = torch.cat(batch_gt, dim=0).cpu().numpy()\n",
        "        accuracy = np.mean(y_pred == y_gt)\n",
        "        return accuracy, avg_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-yobZcQKshV"
      },
      "source": [
        "## Part 2: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wHu--eeZKshV"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------\n",
        "# 2) Data Loading for the Celebrity Faces\n",
        "# ---------------------------------------------\n",
        "def load_celebrity_faces(root_dir, image_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    Loads images from subfolders of `root_dir` (one folder per celebrity).\n",
        "    Returns:\n",
        "        X_gray: Flattened grayscale images for training, shape (num_samples, H*W).\n",
        "        y:      Label array, shape (num_samples,).\n",
        "        label_map: {label_idx: 'celebrity_name'}.\n",
        "        X_color:  Color images (resized but not converted to grayscale),\n",
        "                  shape (num_samples, H, W, 3) in RGB order for display.\n",
        "    \"\"\"\n",
        "    X_input = []\n",
        "    X_color = []\n",
        "    y = []\n",
        "\n",
        "    # subfolders = celebrity names\n",
        "    classes = sorted([\n",
        "        d for d in os.listdir(root_dir)\n",
        "        if os.path.isdir(os.path.join(root_dir, d))\n",
        "    ])\n",
        "\n",
        "    label_map = {idx: celeb for idx, celeb in enumerate(classes)}\n",
        "    name_to_label = {celeb: idx for idx, celeb in enumerate(classes)}\n",
        "\n",
        "    for celeb_name in classes:\n",
        "        celeb_label = name_to_label[celeb_name]\n",
        "        celeb_folder = os.path.join(root_dir, celeb_name)\n",
        "\n",
        "        for i, filename in enumerate(os.listdir(celeb_folder)):\n",
        "            if i >= 100:  # limit to 100 images per class\n",
        "                break\n",
        "            filepath = os.path.join(celeb_folder, filename)\n",
        "            img_bgr = cv2.imread(filepath)\n",
        "            if img_bgr is None:\n",
        "                continue\n",
        "\n",
        "            # Resize color image for display\n",
        "            img_bgr_vis = cv2.resize(img_bgr, (256,256))\n",
        "            # Convert BGR (OpenCV) to RGB for matplotlib\n",
        "            img_rgb_vis = cv2.cvtColor(img_bgr_vis, cv2.COLOR_BGR2RGB)\n",
        "            X_color.append(img_rgb_vis)\n",
        "\n",
        "            # Also create a grayscale copy for training\n",
        "            img_bgr = cv2.resize(img_bgr, image_size)\n",
        "            X_input.append(img_bgr)\n",
        "\n",
        "            y.append(celeb_label)\n",
        "\n",
        "    X_color = np.array(X_color, dtype=np.uint8)  # (num_samples, H, W, 3)\n",
        "    X_input = np.array(X_input, dtype=np.float32)  # (num_samples, H', W', 3)\n",
        "    y = np.array(y, dtype=np.int32)\n",
        "\n",
        "    return X_input, y, label_map, X_color\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TeDq_pQCKshW"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------\n",
        "# 3) Label-Wise k-Fold Splitting (Manual Stratification)\n",
        "# ---------------------------------------------------\n",
        "def labelwise_kfold_split(X, y, k=5, shuffle=True, random_state=None):\n",
        "    \"\"\"\n",
        "    Manually perform a label-wise k-fold split.\n",
        "    Returns list of (train_indices, test_indices) for each fold.\n",
        "    Ensures each label's samples appear in all folds.\n",
        "    \"\"\"\n",
        "    assert len(X) == len(y), \"X and y must have same length.\"\n",
        "\n",
        "    label_indices_map = {}\n",
        "    unique_labels = np.unique(y)\n",
        "\n",
        "    # gather indices by label\n",
        "    for label in unique_labels:\n",
        "        label_indices = np.where(y == label)[0]\n",
        "        label_indices_map[label] = label_indices\n",
        "\n",
        "    # shuffle if needed\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    if shuffle:\n",
        "        for label in unique_labels:\n",
        "            rng.shuffle(label_indices_map[label])\n",
        "\n",
        "    # partition each label's indices into k folds\n",
        "    label_folds = {}\n",
        "    for label in unique_labels:\n",
        "        indices = label_indices_map[label]\n",
        "        num_samples_label = len(indices)\n",
        "\n",
        "        fold_sizes = [num_samples_label // k] * k\n",
        "        for i in range(num_samples_label % k):\n",
        "            fold_sizes[i] += 1\n",
        "\n",
        "        start = 0\n",
        "        label_folds[label] = []\n",
        "        for fold_size in fold_sizes:\n",
        "            end = start + fold_size\n",
        "            fold_subset = indices[start:end]\n",
        "            label_folds[label].append(fold_subset)\n",
        "            start = end\n",
        "\n",
        "    # combine folds across labels\n",
        "    folds = []\n",
        "    for i in range(k):\n",
        "        test_indices_list = []\n",
        "        train_indices_list = []\n",
        "        for label in unique_labels:\n",
        "            # i-th subset for label -> test\n",
        "            test_indices_list.append(label_folds[label][i])\n",
        "            # other subsets -> train\n",
        "            for j in range(k):\n",
        "                if j != i:\n",
        "                    train_indices_list.append(label_folds[label][j])\n",
        "\n",
        "        test_indices = np.concatenate(test_indices_list)\n",
        "        train_indices = np.concatenate(train_indices_list)\n",
        "        folds.append((train_indices, test_indices))\n",
        "\n",
        "    return folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KcAEeiCEKshW"
      },
      "outputs": [],
      "source": [
        "root_dir = \"Celebrity_Faces_Dataset\"\n",
        "pca_components=200\n",
        "learning_rate=0.0001\n",
        "k=5\n",
        "num_epochs=10\n",
        "batch_size=32\n",
        "seed=440"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdqaiNkiKshW"
      },
      "source": [
        "## Part 3: Training & Evaluating Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WUrZfRSBKshX",
        "outputId": "e7f18acc-89be-4abc-b3b6-b31d6bc7f4d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1700 images for 17 celebrities.\n",
            "\n",
            "=== Fold 1/5 ===\n",
            "Train: 1360, Test: 340\n",
            "Using device: cpu\n",
            "Epoch 002: Train Loss = 2.427085, Test Loss = 2.427085, Test Accuracy = 21.47%\n",
            "Epoch 004: Train Loss = 2.376633, Test Loss = 2.376633, Test Accuracy = 26.47%\n",
            "Epoch 006: Train Loss = 2.386444, Test Loss = 2.386444, Test Accuracy = 27.94%\n",
            "Epoch 008: Train Loss = 2.353116, Test Loss = 2.353116, Test Accuracy = 26.76%\n",
            "Epoch 010: Train Loss = 2.332457, Test Loss = 2.332457, Test Accuracy = 33.24%\n",
            "=== Fold 2/5 ===\n",
            "Train: 1360, Test: 340\n",
            "Using device: cpu\n",
            "Epoch 002: Train Loss = 2.389485, Test Loss = 2.389485, Test Accuracy = 24.41%\n",
            "Epoch 004: Train Loss = 2.387722, Test Loss = 2.387722, Test Accuracy = 23.53%\n",
            "Epoch 006: Train Loss = 2.421104, Test Loss = 2.421104, Test Accuracy = 28.24%\n",
            "Epoch 008: Train Loss = 2.405987, Test Loss = 2.405987, Test Accuracy = 27.94%\n",
            "Epoch 010: Train Loss = 2.448110, Test Loss = 2.448110, Test Accuracy = 29.41%\n",
            "=== Fold 3/5 ===\n",
            "Train: 1360, Test: 340\n",
            "Using device: cpu\n",
            "Epoch 002: Train Loss = 2.372580, Test Loss = 2.372580, Test Accuracy = 21.18%\n",
            "Epoch 004: Train Loss = 2.339021, Test Loss = 2.339021, Test Accuracy = 22.94%\n",
            "Epoch 006: Train Loss = 2.336806, Test Loss = 2.336806, Test Accuracy = 28.24%\n",
            "Epoch 008: Train Loss = 2.250088, Test Loss = 2.250088, Test Accuracy = 26.47%\n",
            "Epoch 010: Train Loss = 2.326947, Test Loss = 2.326947, Test Accuracy = 28.24%\n",
            "=== Fold 4/5 ===\n",
            "Train: 1360, Test: 340\n",
            "Using device: cpu\n",
            "Epoch 002: Train Loss = 2.378243, Test Loss = 2.378243, Test Accuracy = 22.06%\n",
            "Epoch 004: Train Loss = 2.317533, Test Loss = 2.317533, Test Accuracy = 23.82%\n",
            "Epoch 006: Train Loss = 2.346427, Test Loss = 2.346427, Test Accuracy = 27.06%\n",
            "Epoch 008: Train Loss = 2.307330, Test Loss = 2.307330, Test Accuracy = 27.65%\n",
            "Epoch 010: Train Loss = 2.331037, Test Loss = 2.331037, Test Accuracy = 29.12%\n",
            "=== Fold 5/5 ===\n",
            "Train: 1360, Test: 340\n",
            "Using device: cpu\n",
            "Epoch 002: Train Loss = 2.439813, Test Loss = 2.439813, Test Accuracy = 18.82%\n",
            "Epoch 004: Train Loss = 2.367930, Test Loss = 2.367930, Test Accuracy = 25.88%\n",
            "Epoch 006: Train Loss = 2.341987, Test Loss = 2.341987, Test Accuracy = 26.47%\n",
            "Epoch 008: Train Loss = 2.336909, Test Loss = 2.336909, Test Accuracy = 27.06%\n",
            "Epoch 010: Train Loss = 2.377535, Test Loss = 2.377535, Test Accuracy = 30.00%\n",
            "Average accuracy across 5-folds: 30.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# 4) Main: k-Fold + (Optional) PCA + Viz\n",
        "# ----------------------------------------\n",
        "\n",
        "# 1. Load data\n",
        "X_input, y, label_map, X_color = load_celebrity_faces(root_dir, image_size=(64, 64))\n",
        "print(f\"Loaded {len(X_input)} images for {len(label_map)} celebrities.\\n\")\n",
        "\n",
        "# 2. Normalize grayscale features to [0..1] for training\n",
        "X_input = X_input / 255.0\n",
        "\n",
        "# 3. Perform manual label-wise k-fold splitting\n",
        "folds = labelwise_kfold_split(X_input, y, k=k)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "fold_num = 1\n",
        "accuracy_across_folds = []\n",
        "for train_indices, test_indices in folds:\n",
        "    print(f\"=== Fold {fold_num}/{k} ===\")\n",
        "    fold_num += 1\n",
        "\n",
        "    X_train = X_input[train_indices]\n",
        "    y_train = y[train_indices]\n",
        "    X_test = X_input[test_indices]\n",
        "    y_test = y[test_indices]\n",
        "\n",
        "    print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "\n",
        "    # 4. Train from-scratch logistic regression\n",
        "    model = CNNClassifier(\n",
        "        learning_rate,\n",
        "        num_epochs,\n",
        "        batch_size,\n",
        "        seed,\n",
        "        input_channels=3,\n",
        "        image_size=(64, 64),\n",
        "        num_classes=len(label_map)\n",
        "    )\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        ave_loss = model.train_epoch(X_train, y_train)\n",
        "        accuracy, ave_loss = model.validate(X_test, y_test)\n",
        "        if (epoch+1) % 2 == 0:\n",
        "            print(f\"Epoch {epoch+1:03d}: Train Loss = {ave_loss:.6f}, Test Loss = {ave_loss:.6f}, Test Accuracy = {accuracy*100:.2f}%\")\n",
        "\n",
        "    accuracy_across_folds.append(accuracy)\n",
        "\n",
        "ave_accuracy = sum(accuracy_across_folds) / len(accuracy_across_folds)\n",
        "print(f\"Average accuracy across {k}-folds: {ave_accuracy*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}